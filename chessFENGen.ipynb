{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nfrom random import shuffle\nfrom PIL import Image\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import Conv2D\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.optimizers import SGD\nfrom keras import regularizers\n\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Convolution2D\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = 12000\ntest_size = 4000\n\nimage_size = 256\nblock_size = 32 #256/8\ninput_shape = (32,32,3)\nbatch_size = 64\n\nreg_constant = 0.0001\nlearning_rate = 0.01\nmomentum = 0.9\n\npieces = 'prbnkqPRBNKQ'\nnumbers = '12345678'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = glob.glob(\"../input/dataset/train/*.jpeg\")\ntest = glob.glob(\"../input/dataset/test/*.jpeg\")\n\nshuffle(train)\nshuffle(test)\n\ntrain = train[:train_size]\ntest = test[:test_size]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_fen(fileLocation):\n    fileName = os.path.basename(fileLocation)\n    return os.path.splitext(fileName)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(get_fen(train[0]))\nprint(get_fen(train[1]))\nprint(get_fen(train[2]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#12 pieces, need to one hot encode a the board with 13 possible values\ndef one_hot_encode(fen):\n    fen = fen.replace(\"-\", \"\")\n    \n    eye = np.eye(13)\n    out = np.zeros((0, 13))\n    \n    for char in fen:\n        if (char in numbers):\n            toAppend = np.tile(eye[12], (int(char), 1))\n        else:\n            piece_index = pieces.index(char)\n            toAppend =  eye[piece_index].reshape((1, 13))\n        out = np.append(out, toAppend, axis=0)\n    \n    return out\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#input is 64 by 13\ndef one_hot_decode(one_hot):\n    #one_hot = np.resize(one_hot, (8,8,13))\n    out = ''\n    for i in range(8):\n        for j in range(8):\n            #eyeInv, = np.where(one_hot[i][j]==1)[0]\n            eyeInv = one_hot[i][j]\n            if (eyeInv == 12):\n                out += ' '\n            else:\n                out += pieces[eyeInv]\n        if (i<7):\n            out += '-'\n    \n    for i in range(8, 0, -1):\n        out = out.replace(i*' ', str(i))\n    \n    return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_image_data(image_location):\n    image = np.array(Image.open(image_location).resize([image_size,image_size]))/255\n    out = np.zeros((64, block_size, block_size, 3))\n    for i in range(8):\n        for j in range(8):\n            out[i*8 + j] = image[i*block_size:(i+1)*block_size,j*block_size:(j+1)*block_size]\n    \n    return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_training_data(data):\n    for i in range(len(data)):\n        image_location = data[i]\n        fen = get_fen(image_location)\n        x = generate_image_data(image_location)\n        y = one_hot_encode(fen)\n    \n        yield x, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"next(generate_prediction(train))[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_training_data(data, batch_size):\n    for i in range(len(data)//batch_size):\n        x = np.zeros((batch_size, 64, block_size, block_size, 3))\n        y = np.zeros((batch_size, 64, 13))\n        for j in range(batch_size): \n            image_location = data[i*batch_size + j]\n            fen = get_fen(image_location)\n            x[j] = generate_image_data(image_location)\n            y[j] = one_hot_encode(fen)\n    \n        yield x, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_prediction(data):\n    for i in range(len(data)):\n        image_location = data[i]\n        yield generate_image_data(image_location)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_prediction(data, batch_size):\n    for i in range(len(data)//batch_size):\n        prediction = np.zeros((batch_size, 64, block_size, block_size, 3))\n        for j in range(batch_size): \n            image_location = data[i*batch_size + j]\n            prediction[j] = generate_image_data(image_location)\n    \n        yield prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#build model\na = Input(shape=(input_shape))\nx = Conv2D(16, [3, 3], padding='same', bias_initializer='random_uniform')(a)\nx = LeakyReLU()(x)\nx = Conv2D(32, [3, 3], padding='same', bias_initializer='random_uniform')(x)\nx = LeakyReLU()(x)\nx = Conv2D(64, [3, 3], padding='same', bias_initializer='random_uniform')(x)\nx = LeakyReLU()(x)\nx = Flatten()(x)\nx = Dense(128, bias_initializer='random_uniform')(x)\nx = LeakyReLU()(x)\nx = Dropout(0.4)(x)\nx = Dense(13, activation='softmax', bias_initializer= 'random_uniform')(x)\n\nmodel = Model(inputs = [a], outputs = [x])\nmodel.compile(loss='categorical_crossentropy', optimizer=SGD(lr = learning_rate, momentum = momentum),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(generate_training_data(train), steps_per_epoch=train_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = (model.predict_generator(generate_prediction(test), len(test)))\npredictions_processed = predictions.reshape(-1, 8, 8, 13).argmax(axis=3)\nfen_predictions = np.array([one_hot_decode(y) for y in predictions_processed])\nfen_real = np.array([get_fen(y_real) for y_real in test])\n\nacc = (fen_predictions == fen_real).astype(float).mean()\n\nprint(\"Accuracy is: \" + str(acc))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}